# ADR-003: Lock Provider Interface and In-Memory Implementation

## Status

Implemented

## Context

Concurrent capture requests for the same payment create race conditions that must be serialized. ADR-001 Section 11 establishes that the `CapturePayment` use case requires per-payment locking to ensure:

- Only one capture attempt is processed at a time per payment
- Idempotency checks and state transitions are atomic
- Time comparisons are consistent within the critical section

This ADR defines the `LockProvider` interface and its in-memory implementation for Stage 1. The goal is to establish correctness guarantees in a single-process environment before introducing database-level or distributed locking.

## Decision

### 1. Port in Application Layer

The `LockProvider` interface (port) lives in the **application layer**. Implementations live in the **infrastructure layer**.

```
src/payments_core/
├── application/
│   └── ports/
│       └── lock_provider.py    # Abstract interface
└── infrastructure/
    └── locking.py              # InMemoryLockProvider, NoOpLockProvider
```

This follows Clean Architecture and maintains consistency with `TimeProvider` (ADR-002): the application layer defines what it needs, infrastructure provides it.

### 2. Interface Definition

We use **ABC** (Abstract Base Class) with a **context manager** pattern for explicit interface enforcement and guaranteed lock release.

```python
from __future__ import annotations

from abc import ABC, abstractmethod
from collections.abc import Iterator
from contextlib import contextmanager


class LockProvider(ABC):
    """Port for resource-level locking.

    Contract:
    - acquire() MUST serialize access to the same resource_id
    - acquire() MUST release the lock when the context exits (normal or exception)
    - acquire() MUST be blocking (waits until lock is available)
    - Different resource_ids MAY be acquired concurrently

    The context manager pattern ensures locks are always released,
    even when exceptions occur within the critical section.
    """

    @abstractmethod
    @contextmanager
    def acquire(self, resource_id: str) -> Iterator[None]:
        """Acquire a lock for the given resource ID.

        Args:
            resource_id: Canonical string identifier for the resource.
                         Must be stable and deterministic (e.g., str(payment_id.value)).

        Yields:
            None. The lock is held for the duration of the context.

        Usage:
            with lock_provider.acquire("payment-uuid-string"):
                # Critical section - lock is held
                ...
            # Lock is released here
        """
```

**Tooling note**: The `@abstractmethod` + `@contextmanager` combination can confuse some linters and type checkers. If mypy/pyright reports errors, an equivalent tooling-friendly signature is:

```python
from contextlib import AbstractContextManager

@abstractmethod
def acquire(self, resource_id: str) -> AbstractContextManager[None]: ...
```

Both shapes are semantically identical; choose based on tooling compatibility.

### 3. Why Context Manager Pattern

The `@contextmanager` decorator combined with `Iterator[None]` is the idiomatic Python pattern for resource acquisition. We evaluated several alternatives:

#### Option A: Context Manager with `@contextmanager` (Chosen)

```python
@abstractmethod
@contextmanager
def acquire(self, resource_id: str) -> Iterator[None]:
    """Acquire a lock for the given resource ID."""
```

**Advantages:**
- **Guaranteed cleanup**: The `finally` block in implementations ensures lock release even on exceptions
- **Idiomatic Python**: Standard pattern recognized by all Python developers
- **Static analysis support**: Type checkers understand `Iterator[None]` from `contextmanager`
- **Composable**: Works with `with` statement, enabling clear critical section boundaries

#### Option B: Explicit acquire/release Methods

```python
@abstractmethod
def acquire(self, resource_id: str) -> None: ...

@abstractmethod
def release(self, resource_id: str) -> None: ...
```

**Why rejected:**
- **Error-prone**: Callers must remember to call `release()` in a `finally` block
- **Exception-unsafe**: Easy to forget cleanup, causing deadlocks
- **More code**: Every call site needs try/finally boilerplate

#### Option C: `__enter__`/`__exit__` Protocol (Class-based Context Manager)

```python
class Lock:
    def __enter__(self) -> None: ...
    def __exit__(self, exc_type, exc_val, exc_tb) -> None: ...

@abstractmethod
def acquire(self, resource_id: str) -> Lock: ...
```

**Why rejected:**
- **Over-engineered**: Requires a separate `Lock` class
- **No benefit**: `@contextmanager` achieves the same with less code
- **Type complexity**: Additional class hierarchy for no practical gain

#### Option D: Async Context Manager

```python
@abstractmethod
async def acquire(self, resource_id: str) -> AsyncIterator[None]: ...
```

**Why rejected for Stage 1:**
- **Premature complexity**: Stage 1 uses synchronous code
- **Threading model**: In-memory implementation uses `threading.Lock`, which is synchronous
- **Future consideration**: Async locking may be introduced with database implementations

### 4. Why `threading.Lock`

The in-memory implementation uses Python's `threading.Lock` primitive. We evaluated several alternatives:

#### Option A: `threading.Lock` (Chosen)

```python
from threading import Lock

lock = Lock()
lock.acquire()  # Blocks until available
try:
    # Critical section
finally:
    lock.release()
```

**Advantages:**
- **Simple**: Minimal API, well-understood semantics
- **Efficient**: Implemented in C, minimal overhead
- **Non-reentrant**: Same-thread re-acquisition deadlocks (see Section 7 for implications)

**Characteristics:**
- **No fairness guarantee**: Lock acquisition order is OS-dependent, not FIFO

#### Option B: `threading.RLock` (Reentrant Lock)

```python
from threading import RLock

lock = RLock()
lock.acquire()  # Same thread can acquire multiple times
lock.acquire()  # Does not block
```

**Why rejected:**
- **Hides bugs**: Reentrant acquisition often indicates design problems
- **Not needed**: Our use case has single acquisition per operation
- **Overhead**: Tracks owning thread, slightly slower

#### Option C: `asyncio.Lock`

```python
import asyncio

lock = asyncio.Lock()
async with lock:
    # Critical section
```

**Why rejected for Stage 1:**
- **Wrong concurrency model**: Designed for async/await, not threads
- **Not thread-safe**: Cannot be used across threads
- **Future consideration**: May be relevant for async implementations

#### Option D: `multiprocessing.Lock`

```python
from multiprocessing import Lock

lock = Lock()  # Works across processes
```

**Why rejected:**
- **Over-engineered**: Stage 1 is single-process
- **Overhead**: IPC overhead for cross-process synchronization
- **Not needed**: In-memory state isn't shared across processes anyway

### 5. In-Memory Implementation: Two-Phase Locking Pattern

`InMemoryLockProvider` uses a **two-phase locking pattern** to safely manage per-resource locks:

```python
from __future__ import annotations

from collections.abc import Iterator
from contextlib import contextmanager
from threading import Lock


class InMemoryLockProvider(LockProvider):
    """In-memory lock provider using per-resource locks.

    Implementation uses two-phase locking:
    1. Global lock protects the lock dictionary during lookup/creation
    2. Resource lock serializes access to the specific resource

    This pattern ensures:
    - No race condition when creating new resource locks
    - Minimal contention (global lock held only briefly)
    - Per-resource parallelism (different resources lock independently)

    Limitations:
    - Single-process only (locks don't work across processes)
    - Unbounded memory growth (locks are never evicted)
    - Not suitable for production with multiple instances
    """

    def __init__(self) -> None:
        self._locks: dict[str, Lock] = {}
        self._global_lock = Lock()

    @contextmanager
    def acquire(self, resource_id: str) -> Iterator[None]:
        # Phase 1: Get or create the resource-specific lock
        # Global lock ensures thread-safe dictionary access
        with self._global_lock:
            if resource_id not in self._locks:
                self._locks[resource_id] = Lock()
            lock = self._locks[resource_id]
        # Global lock is released here - other resources can proceed

        # Phase 2: Acquire the resource-specific lock
        # Using context manager ensures release even on exception
        with lock:
            yield
```

#### Why Two-Phase Locking?

**Problem**: Multiple threads may simultaneously request a lock for a resource that doesn't exist yet.

**Naive approach (incorrect):**
```python
# WRONG: Race condition between check and creation
if resource_id not in self._locks:      # Thread A checks
                                         # Thread B checks (also True)
    self._locks[resource_id] = Lock()   # Thread A creates Lock_1
                                         # Thread B creates Lock_2 (overwrites!)
lock = self._locks[resource_id]         # Thread A gets Lock_2
                                         # Thread B gets Lock_2
# Both threads have the SAME lock object, but Thread A lost its reference
# to Lock_1, which may still be held by another thread
```

**Two-phase approach (correct):**
```python
# CORRECT: Global lock serializes dictionary access
with self._global_lock:                  # Thread A acquires global
                                         # Thread B blocks on global
    if resource_id not in self._locks:
        self._locks[resource_id] = Lock()
    lock = self._locks[resource_id]      # Thread A gets Lock_1
                                         # Thread A releases global
                                         # Thread B acquires global
                                         # Thread B gets Lock_1 (same lock!)
                                         # Thread B releases global
lock.acquire()                           # Both threads compete for Lock_1
```

#### Alternative: `defaultdict` with Lock

```python
from collections import defaultdict
from threading import Lock

# WRONG: defaultdict is not thread-safe
self._locks = defaultdict(Lock)
lock = self._locks[resource_id]  # Race condition on missing key
```

**Why rejected**: `defaultdict.__getitem__` is not atomic. The default factory can be called multiple times for the same key under concurrent access.

### 6. Lock Key Requirements

The `resource_id` passed to `acquire()` must be:

| Requirement | Rationale | Example |
|-------------|-----------|---------|
| **Canonical** | Same resource always produces same key | `str(payment_id.value)` not `payment_id` |
| **Stable** | Key doesn't change across serialization | UUID string, not object hash |
| **Deterministic** | No randomness or time-dependence | Not `f"{payment_id}-{uuid4()}"` |

**Usage in CapturePayment:**
```python
with lock_provider.acquire(str(payment_id.value)):
    # Critical section
```

This ensures the same payment always maps to the same lock, regardless of how `PaymentId` is instantiated or deserialized.

### 7. Re-Entrancy, Lock Ordering, and Time Binding

Per ADR-001 and ADR-002, the use case must:

1. **Acquire lock first**: Before any state checks or modifications
2. **Fetch time inside critical section**: Ensures time comparison is consistent with state
3. **Single lock per operation**: No nested lock acquisitions (prevents deadlocks)

**Re-entrancy constraint**: The use case **must not** attempt to acquire the same resource lock re-entrantly. `threading.Lock` is non-reentrant—same-thread re-acquisition will **deadlock indefinitely**, not raise an exception.

```python
# WRONG: This will deadlock
with lock_provider.acquire(resource_id):
    # ... some code ...
    with lock_provider.acquire(resource_id):  # Deadlock: same thread, same lock
        pass
```

**Multi-resource locking**: If future use cases require locking multiple resources (e.g., transfer between two payments), they **must** define a global lock ordering rule to prevent deadlock. A common pattern is lexicographic ordering by resource ID:

```python
# Future pattern (not needed for Stage 1):
ids = sorted([payment_id_a, payment_id_b])
with lock_provider.acquire(str(ids[0].value)):
    with lock_provider.acquire(str(ids[1].value)):
        # Both resources locked in consistent order
        pass
```

Stage 1 requires only single-resource locking, so this complexity is deferred.

```python
class CapturePaymentUseCase:
    def execute(self, request: CapturePaymentRequest) -> CapturePaymentResponse:
        with self._lock_provider.acquire(str(request.payment_id.value)):
            # Time fetched INSIDE critical section (per ADR-002)
            now = self._time_provider.now()

            # 1. Check idempotency (return early if replay)
            existing = self._capture_repo.get_by_idempotency_key(
                request.payment_id, request.idempotency_key
            )
            if existing:
                return self._handle_idempotent_replay(existing, request)

            # 2. Fetch and validate payment
            payment = self._payment_repo.get(request.payment_id)
            if payment is None:
                raise PaymentNotFoundError(...)

            # 3. Check capture eligibility
            if payment.state == PaymentState.CAPTURED:
                raise PaymentAlreadyCapturedError(...)
            if not payment.can_capture(now):
                raise PaymentExpiredError(...)

            # 4. Create capture and update payment
            capture = Capture.create(...)
            payment.capture(now, request.amount_cents)

            self._capture_repo.save(capture)
            self._payment_repo.save(payment)

            return CapturePaymentResponse(...)
```

**Critical**: Fetching `now` before acquiring the lock creates a race condition where time advances between the check and the state modification.

### 8. Thread Safety Guarantees

`InMemoryLockProvider` provides these guarantees:

| Guarantee | Scope | Limitation |
|-----------|-------|------------|
| **Mutual exclusion** | Same `resource_id` | Single process only |
| **Deadlock avoidance** | Single lock per operation, no re-entrancy | Violated constraints cause deadlock |
| **Exception-safe** | Always releases lock | Context manager semantics guarantee release |

**Not guaranteed:**
- **Cross-process locking**: Use database locks for multi-instance deployments
- **Fairness**: Lock acquisition order is OS-dependent, not FIFO
- **Bounded memory**: Lock dictionary grows indefinitely (see Future Work)

### 9. Test Implementation: NoOpLockProvider

For unit tests that don't require concurrency verification, `NoOpLockProvider` skips actual locking:

```python
class NoOpLockProvider(LockProvider):
    """Lock provider that performs no locking.

    Use this for unit tests where:
    - Concurrency is not being tested
    - Tests are single-threaded
    - Lock overhead is unnecessary

    Do NOT use for:
    - Integration tests with concurrent requests
    - Any test verifying race condition handling
    """

    @contextmanager
    def acquire(self, resource_id: str) -> Iterator[None]:
        yield  # No-op: no lock acquired or released
```

**When to use each provider:**

| Test Type | Provider | Rationale |
|-----------|----------|-----------|
| Unit tests (single-threaded) | `NoOpLockProvider` | No concurrency, faster execution |
| Concurrency unit tests | `InMemoryLockProvider` | Verify race condition handling |
| Integration tests | `InMemoryLockProvider` | Realistic behavior |

### 10. Concurrency Tests

The following tests **must** be implemented to verify the locking guarantees:

#### Test 1: Same Payment, Same Idempotency Key (Concurrent)

Two threads submit capture requests with identical `(payment_id, idempotency_key)` simultaneously.

**Expected behavior:**
- Exactly one `Capture` record is created
- Both threads receive the same result (idempotent replay)
- No duplicate writes, no inconsistent state

#### Test 2: Same Payment, Different Idempotency Keys (Concurrent)

Two threads submit capture requests for the same payment with different idempotency keys.

**Expected behavior:**
- Exactly one capture succeeds (first to acquire lock and complete)
- The other receives `PaymentAlreadyCapturedError`
- Payment transitions to `CAPTURED` exactly once

#### Test 3: Lock Release on Exception

A thread acquires a lock, then raises an exception within the critical section.

**Expected behavior:**
- Lock is released despite the exception (context manager guarantee)
- Subsequent acquisition by another thread succeeds immediately
- No deadlock occurs

```python
def test_lock_released_on_exception():
    lock_provider = InMemoryLockProvider()
    resource_id = "test-resource"

    # First acquisition raises exception
    with pytest.raises(RuntimeError):
        with lock_provider.acquire(resource_id):
            raise RuntimeError("Simulated failure")

    # Second acquisition should succeed (lock was released)
    with lock_provider.acquire(resource_id):
        pass  # No deadlock
```

### 11. Usage in Use Cases

The `LockProvider` is injected into use cases via constructor:

```python
class CapturePaymentUseCase:
    def __init__(
        self,
        lock_provider: LockProvider,
        time_provider: TimeProvider,
        payment_repo: PaymentRepository,
        capture_repo: CaptureRepository,
    ) -> None:
        self._lock_provider = lock_provider
        self._time_provider = time_provider
        self._payment_repo = payment_repo
        self._capture_repo = capture_repo
```

This enables:
- **Testing**: Inject `NoOpLockProvider` or `InMemoryLockProvider` as needed
- **Production flexibility**: Swap implementations without changing use case code
- **Clear dependencies**: All infrastructure dependencies are explicit

## Consequences

### Positive

- **Testable**: Lock behavior can be controlled via dependency injection
- **Clean Architecture**: Port in application, implementation in infrastructure
- **Correct**: Two-phase locking prevents race conditions in lock creation
- **Exception-safe**: Context manager guarantees lock release
- **Simple**: Minimal interface covers all Stage 1 requirements
- **Explicit**: Lock acquisition boundaries are clear in code

### Negative

- **Single-process only**: In-memory locks don't work across instances
- **Unbounded memory**: Lock dictionary grows without eviction
- **Blocking**: No timeout or try-acquire for advanced patterns
- **No fairness guarantee**: Lock acquisition order is platform-dependent

### Related ADRs

- [ADR-001](ADR-001.md): Core Domain Model and In-Memory Correctness (Section 11: Locking Strategy)
- [ADR-002](ADR-002.md): Time Provider Interface and Implementation (time binding with locks)

### Future Work

- ADR for database-level locking (`SELECT FOR UPDATE` with PostgreSQL)
- ADR for distributed locking (Redis, PostgreSQL advisory locks)
- Lock timeout and deadlock detection for production resilience

#### Bounded Memory Strategies

The current implementation has unbounded memory growth. Future improvements could use:

| Strategy | Description | Trade-off |
|----------|-------------|-----------|
| **Striped locks** | Fixed array of N locks; `hash(resource_id) % N` selects stripe | Bounded memory, reduced concurrency (unrelated resources may share a stripe) |
| **WeakValueDictionary** | Locks eligible for GC when not referenced | Lock may be collected between lookup and acquire; also racy across threads unless acquisition holds a strong reference throughout |
| **LRU eviction** | Evict least-recently-used locks when map exceeds threshold | Complex; must ensure evicted lock isn't currently held |

For Stage 1, unbounded growth is acceptable—payment volume is bounded by test scenarios.
